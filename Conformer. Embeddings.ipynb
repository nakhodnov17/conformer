{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b922c0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:11:27.053284Z",
     "start_time": "2022-12-19T12:11:26.937526Z"
    },
    "cellId": "rtu6mtm3ckdhyebmh73uh"
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fdc2bf11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:11:27.087110Z",
     "start_time": "2022-12-19T12:11:27.056905Z"
    },
    "cellId": "mz0t6vzb95z0ezs6ppie"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Video\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38793d",
   "metadata": {
    "cellId": "pxnuldnatncp1lahm9jetr",
    "execution_id": "2048cffe-2fa8-4c7f-997b-46a1d87b1803"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "11f51665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:11:52.626587Z",
     "start_time": "2022-12-19T12:11:27.092077Z"
    },
    "cellId": "99384ya0euru0od5kops6q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c0256c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:05.959275Z",
     "start_time": "2022-12-19T12:11:52.641584Z"
    },
    "cellId": "tf9c9s1m0ngswlwcaane8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import regex\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import GridBox, Audio, HBox, VBox, Box, Label, Layout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib_inline\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "955dcc16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:06.051593Z",
     "start_time": "2022-12-19T12:12:05.964920Z"
    },
    "cellId": "13ewwph0r29a679lqewdsqt"
   },
   "outputs": [],
   "source": [
    "def sample_dataset(dataset, n=4):\n",
    "    grid = []\n",
    "    for idx in range(n):\n",
    "        grid.append(\n",
    "            VBox([\n",
    "                Label('{0:d}, {1}, {2:.1f}'.format(idx, dataset['text'][idx], dataset.get('duration', dataset['audio_len'])[idx])),\n",
    "                Audio.from_file(dataset['audio_path'][idx], autoplay=False, loop=False),\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    return HBox([VBox(grid[0::2]), VBox(grid[1::2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d4f1687c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:06.117704Z",
     "start_time": "2022-12-19T12:12:06.057683Z"
    },
    "cellId": "hc2uys3stp7g08reucbop4"
   },
   "outputs": [],
   "source": [
    "base_path = '/home/jupyter/mnt/datasets'\n",
    "\n",
    "libri_speech_base_path = os.path.join(base_path, 'LibriSpeech_ds')\n",
    "golos_base_path = os.path.join(base_path, 'golos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "266d0126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:35.827854Z",
     "start_time": "2022-12-19T12:12:06.127660Z"
    },
    "cellId": "6s08r0ju4ix8cvn38a09g6"
   },
   "outputs": [],
   "source": [
    "from src.dataset import get_libri_speech_dataset, get_golos_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4f7e597e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.927056Z",
     "start_time": "2022-12-19T12:12:39.765008Z"
    },
    "cellId": "onzgw7lc28nw9lt6wsc7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1400 objects\n"
     ]
    }
   ],
   "source": [
    "libri_speech_dev = get_libri_speech_dataset(libri_speech_base_path, split='dev')\n",
    "\n",
    "print('Loaded {0:d} objects'.format(len(libri_speech_dev['audio_path'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "417a3ad8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:36.396693Z",
     "start_time": "2022-12-19T12:12:36.186059Z"
    },
    "cellId": "ns33zr2ogg8tlkhu598x9"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer model\n",
    "sp_tokenizer = sentencepiece.SentencePieceProcessor(model_file='tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3273e7aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:36.515656Z",
     "start_time": "2022-12-19T12:12:36.406856Z"
    },
    "cellId": "xxkkeujjmpwmixeqinv4"
   },
   "outputs": [],
   "source": [
    "from src.dataset import AudioDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a182f313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:37.200460Z",
     "start_time": "2022-12-19T12:12:36.522372Z"
    },
    "cellId": "1apo5frt2pr9on3v7upvz5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:190: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_16_pushkin_0039.wav',\n",
       " tensor([-4.8218e-03, -4.8828e-03, -4.7913e-03,  ...,  3.0518e-05,\n",
       "          0.0000e+00,  3.0518e-05]),\n",
       " 34720,\n",
       " 'дай бог чтоб просветились мы',\n",
       " tensor([ 1, 48, 13,  1, 85, 35, 66, 25, 88,  7, 70, 74, 27, 71,  1,  4, 31]),\n",
       " 17)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libri_speech_dev_ds = AudioDataset(libri_speech_dev, sp_tokenizer, min_duration=1.36, max_duration=10.96)\n",
    "libri_speech_dev_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7b0d7822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:37.698906Z",
     "start_time": "2022-12-19T12:12:37.206208Z"
    },
    "cellId": "vznhmd4cd1wwsoeod9bqn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_path': ['/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_16_pushkin_0039.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_19_pushkin_0090.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_31_pushkin_0052.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_20_pushkin_0033.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_19_pushkin_0055.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_13_pushkin_0030.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_17_pushkin_0055.wav',\n",
       "  '/home/jupyter/mnt/datasets/LibriSpeech_ds/dev/audio/5397/2145/poemi_19_pushkin_0103.wav'],\n",
       " 'audio': tensor([[-4.8218e-03, -4.8828e-03, -4.7913e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0071e-03,  1.0071e-03,  8.8501e-04,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-9.3079e-03, -1.1719e-02, -1.3184e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 4.9713e-02,  6.1890e-02,  6.3538e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 5.7678e-03,  5.3406e-03,  4.8523e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 6.1035e-05,  1.5259e-04,  9.1553e-05,  ...,  0.0000e+00,\n",
       "           1.5259e-04,  6.1035e-05]]),\n",
       " 'audio_len': tensor([34720, 34720, 35200, 35520, 35520, 36160, 36480, 36800]),\n",
       " 'text': ['дай бог чтоб просветились мы',\n",
       "  'но где же первый званый гость',\n",
       "  'вот что хочется мне зоинька',\n",
       "  'в нем только лень и непокорство',\n",
       "  'тесним мы шведов рать за ратью',\n",
       "  'куда свой тайный путь направил',\n",
       "  'давно в ней искра разгоралась',\n",
       "  'в нем мрачный дух не знал покоя'],\n",
       " 'tokens': tensor([[  1,  48,  13,   1,  85,  35,  66,  25,  88,   7,  70,  74,  27,  71,\n",
       "            1,   4,  31,   0,   0,   0,   0],\n",
       "         [  1,  19,  92,  49,   1,  61,  52,  77,   8,  31,  13,   1,  17,   8,\n",
       "            3,  55,  13,   1,  29, 116,   0],\n",
       "         [ 99,   9,  66, 123,  60,   9,  54,   1,   4,  65,   1,  17,  15,   6,\n",
       "          109,  45,   0,   0,   0,   0,   0],\n",
       "         [ 18,  21,   4,  79,  58,  37,   1,   5,   2, 109,  14,  21, 110,  37,\n",
       "           32,  40,  42,   0,   0,   0,   0],\n",
       "         [  1,  47,   7,  22,   4,   1,   4,  31,   1,  44,  70,  86,   8,   1,\n",
       "           24,  56,  63,   1,  24,  56,  28],\n",
       "         [  1, 106,  48,  10,  42,  13,   1,  83,  13,  55,  13,  52,  12,  56,\n",
       "           33,  34,  24,   8,   6,   5,   0],\n",
       "         [  1,  48,   8,  19,  18,  21,  13,  14,   7,  41,  24,   1,  24,  17,\n",
       "           29,  24,  30,  71,   0,   0,   0],\n",
       "         [ 18,  21,   4,   1,   4,  24,  53,  55,  13,   1,  94,  26,  21,   1,\n",
       "           17,  57,   5,  23,  37,  11,   0]]),\n",
       " 'tokens_len': tensor([17, 20, 16, 17, 21, 20, 18, 20])}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "num_workers = 0\n",
    "\n",
    "libri_speech_dev_dl = DataLoader(\n",
    "    libri_speech_dev_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=False, collate_fn=collate_fn\n",
    ")\n",
    "batch = next(iter(libri_speech_dev_dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5804943b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:37.891272Z",
     "start_time": "2022-12-19T12:12:37.705163Z"
    },
    "cellId": "432kb5fnu1gloyos4sc7s"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b8344ac9940aeb23ad43ae27b445e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(Label(value='0, дай бог чтоб просветились мы, 34720.0'), Audio(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dataset(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a3f57690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.011794Z",
     "start_time": "2022-12-19T12:12:37.897281Z"
    },
    "cellId": "rgopgjjzwdjcrx690ffq"
   },
   "outputs": [],
   "source": [
    "from src.preprocessor import AudioToMelSpectrogramPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3bcfe264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.193554Z",
     "start_time": "2022-12-19T12:12:38.018065Z"
    },
    "cellId": "jt8bpb4zomn13xj4ltdws"
   },
   "outputs": [],
   "source": [
    "preprocessor = AudioToMelSpectrogramPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b0256657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.351922Z",
     "start_time": "2022-12-19T12:12:38.196891Z"
    },
    "cellId": "16rsn621sz5dwzs7xzw0x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "features, feature_lengths = preprocessor(batch['audio'], batch['audio_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fba46e",
   "metadata": {
    "cellId": "uduczuy2ksdxu1wdj8w7d"
   },
   "source": [
    "# Implement `src.preprocessor.ConvSubsampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b6faff0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.454033Z",
     "start_time": "2022-12-19T12:12:38.366098Z"
    },
    "cellId": "mdqi67hjuaq4i9ehpnfmnu"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def deterministic_fill(module, seed=64, verbose=False, eps=1e-5):\n",
    "    module = copy.deepcopy(module)\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "     \n",
    "    for name, param in sorted(module.state_dict().items()):\n",
    "        if verbose:\n",
    "            print(name)\n",
    "        data = torch.tensor(rng.random(param.shape), dtype=param.dtype, device=param.device)\n",
    "        data = (data - data.mean()) / (data.std() + eps)\n",
    "        param.data.copy_(data)\n",
    "        \n",
    "    return module\n",
    "\n",
    "def diff_check(left, right, decimals):\n",
    "    return abs(float(left) - float(right)) < 10 ** (-decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e1072109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.568965Z",
     "start_time": "2022-12-19T12:12:38.473350Z"
    },
    "cellId": "hf83utjpio9u24e4kqc878"
   },
   "outputs": [],
   "source": [
    "from src.preprocessor import ConvSubsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7360bb5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.672105Z",
     "start_time": "2022-12-19T12:12:38.575547Z"
    },
    "cellId": "85j78unwpi6nfhv7zg2st"
   },
   "outputs": [],
   "source": [
    "pre_encode = ConvSubsampling(\n",
    "    feat_in=80, feat_out=176,\n",
    "    sampling_num=2, conv_channels=176\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c60cae21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:38.862866Z",
     "start_time": "2022-12-19T12:12:38.678491Z"
    },
    "cellId": "y2pcrw6au97h0c3puno0s"
   },
   "outputs": [],
   "source": [
    "features_enc, feature_enc_lengths = pre_encode(torch.transpose(features, 1, 2), feature_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d0d27824",
   "metadata": {
    "cellId": "q4pxyd75kgjerycru2urm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvSubsampling(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (out): Linear(in_features=3520, out_features=176, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a755ab8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.052865Z",
     "start_time": "2022-12-19T12:12:38.873262Z"
    },
    "cellId": "ixb00hvzjkm13ceha804usm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1817.9126, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-149c47ae0d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrnd_feature_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m54\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m59\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_features_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdiff_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_features_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1817.9062\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocessor.eval()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "rnd_audio = torch.tensor(rng.random([13, 12345]), dtype=torch.float32)\n",
    "rnd_audio_len = torch.tensor(rng.integers(low=0, high=12345, size=[13]), dtype=torch.long)\n",
    "rnd_features, rnd_feature_lengths = preprocessor(rnd_audio, rnd_audio_len)\n",
    "\n",
    "rnd_pre_encode = deterministic_fill(pre_encode, seed=64).eval()\n",
    "rnd_features_enc, rnd_feature_enc_lengths = rnd_pre_encode(torch.transpose(rnd_features, 1, 2), rnd_feature_lengths)\n",
    "\n",
    "assert sum(p.numel() for p in rnd_pre_encode.parameters()) == 900416\n",
    "assert list(rnd_features_enc.shape) == [13, 20, 176]\n",
    "assert rnd_feature_lengths.cpu().tolist() == [43, 48, 34, 32, 54, 45, 41, 59, 21, 4, 72, 16, 31]\n",
    "print(rnd_features_enc.abs().mean())\n",
    "assert diff_check(rnd_features_enc.abs().mean(), 1817.9062, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98128e6c",
   "metadata": {
    "cellId": "wwwjv2y6u788bmhzzgo2p"
   },
   "source": [
    "# Implement `src.preprocessor.RelPositionalEncoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f2723343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.149094Z",
     "start_time": "2022-12-19T12:12:39.062904Z"
    },
    "cellId": "hkjopaqwd9v125avo2gucbb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from src.encoding import RelPositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7df6e5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.285279Z",
     "start_time": "2022-12-19T12:12:39.157914Z"
    },
    "cellId": "14qi5herzstcee469i2oge"
   },
   "outputs": [],
   "source": [
    "pos_enc = RelPositionalEncoding(\n",
    "    d_model=176,\n",
    "    dropout_rate=0.1,\n",
    "    max_len=5000,\n",
    "    xscale=math.sqrt(176),\n",
    "    dropout_rate_emb=0.0,\n",
    ")\n",
    "\n",
    "pos_enc.extend_pe(length=5000, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c21e2fac",
   "metadata": {
    "cellId": "rljdxreskvfzr5reairvv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6376)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_enc.pe.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d4ba3bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.379200Z",
     "start_time": "2022-12-19T12:12:39.300894Z"
    },
    "cellId": "gq12ey6zoa7ptytay3nudr"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-515ec151491f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m176\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdiff_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6366\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert list(pos_enc.pe.shape) == [1, 9999, 176]\n",
    "assert diff_check(pos_enc.pe.abs().mean(), 0.6366, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "79f75934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.540685Z",
     "start_time": "2022-12-19T12:12:39.382536Z"
    },
    "cellId": "6xn2s2f56b88o6pnbdk4eu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39, 176])\n",
      "tensor(24117.3398, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5681)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8b0e8cab8a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_features_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_pos_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdiff_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_features_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24117.2559\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mdiff_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_pos_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5670\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocessor.eval()\n",
    "pre_encode.eval()\n",
    "pos_enc.eval()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "rnd_audio = torch.tensor(rng.random([13, 12345]), dtype=torch.float32)\n",
    "rnd_audio_len = torch.tensor(rng.integers(low=0, high=12345, size=[13]), dtype=torch.long)\n",
    "rnd_features, rnd_feature_lengths = preprocessor(rnd_audio, rnd_audio_len)\n",
    "\n",
    "rnd_pre_encode = deterministic_fill(pre_encode, seed=64).eval()\n",
    "rnd_features_enc, rnd_feature_enc_lengths = rnd_pre_encode(torch.transpose(rnd_features, 1, 2), rnd_feature_lengths)\n",
    "\n",
    "rnd_features_emb, rnd_pos_emb = pos_enc(rnd_features_enc)\n",
    "\n",
    "assert list(rnd_features_emb.shape) == [13, 20, 176]\n",
    "print(rnd_pos_emb.shape)\n",
    "assert list(rnd_pos_emb.shape) == [1, 39, 176]\n",
    "print(rnd_features_emb.abs().mean())\n",
    "print(rnd_pos_emb.abs().mean())\n",
    "assert diff_check(rnd_features_emb.abs().mean(), 24117.2559, 4)\n",
    "assert diff_check(rnd_pos_emb.abs().mean(), 0.5670, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dfa2a9",
   "metadata": {
    "cellId": "65c63fom4gxehsndcnrhsv",
    "execution_id": "d2e1e4ba-c385-4024-a273-990124103f16"
   },
   "source": [
    "# Implement `src.encoder.ConformerEncoder._create_masks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e5fa3b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.688987Z",
     "start_time": "2022-12-19T12:12:39.549566Z"
    },
    "cellId": "fmia9hhcxrdsbrcpbu163"
   },
   "outputs": [],
   "source": [
    "from src.encoder import ConformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5fe53694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T12:12:39.759090Z",
     "start_time": "2022-12-19T12:12:39.693137Z"
    },
    "cellId": "i7o53y82b0dag334utzptt"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6b96134a0541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpad_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConformerEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/average_enjoyer/conformer/src/encoder.py\u001b[0m in \u001b[0;36m_create_masks\u001b[0;34m(max_length, lengths, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_mask' is not defined"
     ]
    }
   ],
   "source": [
    "max_length, lengths = 10, torch.tensor([4, 5, 2, 7], dtype=torch.long)\n",
    "pad_mask, att_mask = ConformerEncoder._create_masks(max_length, lengths, device=torch.device('cpu'))\n",
    "\n",
    "assert list(pad_mask.shape) == [lengths.shape[0], max_length]\n",
    "assert list(att_mask.shape) == [lengths.shape[0], max_length, max_length]\n",
    "\n",
    "assert torch.all(pad_mask.sum(dim=1) == max_length - lengths)\n",
    "assert torch.all(torch.sum(~att_mask, dim=(1, 2)) == lengths ** 2)\n",
    "\n",
    "print(pad_mask, att_mask, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "753f17b2",
   "metadata": {
    "cellId": "3g1x8lhsndpcjyrqbyjuik"
   },
   "outputs": [],
   "source": [
    "from src.attention import RelPositionMultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9ffab4a7",
   "metadata": {
    "cellId": "fdd8997wmufj4yaa78ppq"
   },
   "outputs": [],
   "source": [
    "attention = RelPositionMultiHeadAttention (\n",
    "    n_head=3,\n",
    "    n_feat=9,\n",
    "    dropout_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "da067616",
   "metadata": {
    "cellId": "284jh2461orrri7yuwws1s"
   },
   "outputs": [],
   "source": [
    "ten1 = torch.randn(10, 13, 9)\n",
    "mask = torch.zeros(10, 13, 13)\n",
    "pos_emb = torch.randn(10, 25, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "97f997f8",
   "metadata": {
    "cellId": "lomkgd2llgt0qtolj9mi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 13, 13])\n",
      "torch.Size([10, 3, 13, 3])\n"
     ]
    }
   ],
   "source": [
    "res = attention(ten1, ten1, ten1, mask, pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0ffb7ad8",
   "metadata": {
    "cellId": "763wcblmdawu5kqnu0sqfs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 13, 9])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "94e63d38-3632-42d8-9e39-b2ee1bc72ace",
  "notebookPath": "average_enjoyer/conformer/Conformer. Embeddings.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
