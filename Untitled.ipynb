{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f3bb2bfe",
   "metadata": {
    "cellId": "dvfohurqunk3ofpgj0f7of"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0ad69818",
   "metadata": {
    "cellId": "e7mia9nx6dw6ks0ibie7kw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "from IPython.display import display, HTML, Video\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "22a7a05c",
   "metadata": {
    "cellId": "d0grt2y6r7q34c4rx9i3lf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "51f5eff9",
   "metadata": {
    "cellId": "abbs6igudujmxcpq3fxgb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import regex\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import GridBox, Audio, HBox, VBox, Box, Label, Layout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib_inline\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0a61cf65",
   "metadata": {
    "cellId": "qou4p005w64wph1exgchw"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "base_path = '/home/jupyter/mnt/datasets'\n",
    "\n",
    "libri_speech_base_path = os.path.join(base_path, 'LibriSpeech_ds')\n",
    "golos_base_path = os.path.join(base_path, 'golos')\n",
    "\n",
    "device = torch.device(\"cuda\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "be036951",
   "metadata": {
    "cellId": "xlsjq7fz87jnd92bgs9s4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1400 objects\n",
      "Loaded 54472 objects\n",
      "Loaded 1352 objects\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from src.dataset import get_libri_speech_dataset, get_golos_dataset\n",
    "\n",
    "libri_speech_dev = get_libri_speech_dataset(libri_speech_base_path, split='dev')\n",
    "libri_speech_train = get_libri_speech_dataset(libri_speech_base_path, split='train')\n",
    "libri_speech_test = get_libri_speech_dataset(libri_speech_base_path, split='test')\n",
    "\n",
    "print('Loaded {0:d} objects'.format(len(libri_speech_dev['audio_path'])))\n",
    "print('Loaded {0:d} objects'.format(len(libri_speech_train['audio_path'])))\n",
    "print('Loaded {0:d} objects'.format(len(libri_speech_test['audio_path'])))\n",
    "\n",
    "# Load tokenizer model\n",
    "sp_tokenizer = sentencepiece.SentencePieceProcessor(model_file='tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e1340e7f",
   "metadata": {
    "cellId": "398yspr0ar7v3ehsed2z6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:190: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:190: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:190: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from src.dataset import AudioDataset, collate_fn\n",
    "\n",
    "libri_speech_dev_ds = AudioDataset(libri_speech_dev, sp_tokenizer, min_duration=1.36, max_duration=10.96)\n",
    "libri_speech_train_ds = AudioDataset(libri_speech_train, sp_tokenizer, min_duration=1.36, max_duration=10.96)\n",
    "libri_speech_test_ds = AudioDataset(libri_speech_test, sp_tokenizer, min_duration=1.36, max_duration=10.96)\n",
    "\n",
    "batch_size = 20\n",
    "num_workers = 0\n",
    "\n",
    "libri_speech_dev_dl = DataLoader(\n",
    "    libri_speech_dev_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "libri_speech_train_dl = DataLoader(\n",
    "    libri_speech_train_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "libri_speech_test_dl = DataLoader(\n",
    "    libri_speech_test_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "train_dataloaders = {\n",
    "    'libri_speech/train': libri_speech_train_dl, \n",
    "#     'golos/train': golos_train\n",
    "}\n",
    "\n",
    "validate_dataloaders = {\n",
    "#     'golos/test/crowd': golos_test_crowd,\n",
    "#     'golos/test/farfield': golos_test_farfield,\n",
    "    'libri_speech/dev': libri_speech_dev_dl,\n",
    "    'libri_speech/test': libri_speech_test_dl,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "cf6582bf",
   "metadata": {
    "cellId": "hgp4sej6s7mfzml9v3ewrm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f0eb492b6d0>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "libri_speech_dev_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8b96f34d",
   "metadata": {
    "cellId": "onl9r6f5mzgug12gt7gx5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "batch = next(iter(libri_speech_dev_dl))\n",
    "batch[\"audio\"] = batch[\"audio\"].to(device)\n",
    "batch[\"audio_len\"] = batch[\"audio_len\"].to(device)\n",
    "batch[\"audio\"].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d3caee88",
   "metadata": {
    "cellId": "as11q2daypkvtbqc3jxazj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from src.conformer import Conformer\n",
    "\n",
    "conformer = Conformer()\n",
    "conformer.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2083e8ac",
   "metadata": {
    "cellId": "9scwgryj3acbc2ni71hwvc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "weights = torch.load(\"conformer.pt\")\n",
    "conformer.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a70353b9",
   "metadata": {
    "cellId": "w12nq0mdc77zidjib10zh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.4755e+01, -3.1851e-03, -1.3494e+01,  ..., -2.0284e+01,\n",
      "          -1.8317e+01, -6.8318e+00],\n",
      "         [-4.8094e+01, -2.1501e+00, -1.3310e+01,  ..., -2.8854e+01,\n",
      "          -1.8606e+01, -1.6177e-01],\n",
      "         [-3.9684e+01, -1.2522e+01, -1.3445e+01,  ..., -2.5405e+01,\n",
      "          -2.0685e+01, -6.8880e+00],\n",
      "         ...,\n",
      "         [-3.9987e+01, -1.4132e+01, -1.1525e+01,  ..., -2.1755e+01,\n",
      "          -1.8847e+01, -3.2265e-04],\n",
      "         [-4.0253e+01, -1.3717e+01, -1.1851e+01,  ..., -2.1617e+01,\n",
      "          -1.9078e+01, -2.5627e-04],\n",
      "         [-4.0497e+01, -1.3089e+01, -1.2358e+01,  ..., -2.1578e+01,\n",
      "          -1.9446e+01, -1.7272e-04]],\n",
      "\n",
      "        [[-4.3224e+01, -9.8220e+00, -1.2973e+01,  ..., -2.2265e+01,\n",
      "          -1.9181e+01, -1.2325e-04],\n",
      "         [-4.2678e+01, -5.4410e+00, -1.2212e+01,  ..., -1.9231e+01,\n",
      "          -2.0382e+01, -6.0674e-03],\n",
      "         [-3.1704e+01, -3.2840e+00, -1.1211e+01,  ..., -1.2642e+01,\n",
      "          -1.8116e+01, -4.1934e+00],\n",
      "         ...,\n",
      "         [-4.0068e+01, -1.3436e+01, -1.1649e+01,  ..., -2.1232e+01,\n",
      "          -1.8447e+01, -4.1214e-04],\n",
      "         [-4.0552e+01, -1.3073e+01, -1.2018e+01,  ..., -2.1099e+01,\n",
      "          -1.8833e+01, -2.9214e-04],\n",
      "         [-4.0909e+01, -1.2581e+01, -1.2593e+01,  ..., -2.1283e+01,\n",
      "          -1.9512e+01, -1.8035e-04]],\n",
      "\n",
      "        [[-4.0880e+01, -9.7034e+00, -1.2064e+01,  ..., -1.7736e+01,\n",
      "          -2.0912e+01, -8.4666e-01],\n",
      "         [-3.6861e+01, -7.0552e+00, -1.3300e+01,  ..., -1.6007e+01,\n",
      "          -1.9031e+01, -3.9320e+00],\n",
      "         [-3.5847e+01, -1.0991e+01, -1.2876e+01,  ..., -1.6356e+01,\n",
      "          -2.1343e+01, -4.4982e+00],\n",
      "         ...,\n",
      "         [-3.9425e+01, -1.4965e+01, -1.0967e+01,  ..., -2.1294e+01,\n",
      "          -1.8703e+01, -3.6877e-04],\n",
      "         [-3.9419e+01, -1.4150e+01, -1.1098e+01,  ..., -2.0878e+01,\n",
      "          -1.8724e+01, -3.9903e-04],\n",
      "         [-3.9803e+01, -1.3296e+01, -1.1762e+01,  ..., -2.0962e+01,\n",
      "          -1.9004e+01, -2.6449e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6427e+01, -1.6722e-02, -1.1437e+01,  ..., -1.9090e+01,\n",
      "          -1.7628e+01, -4.6656e+00],\n",
      "         [-4.2696e+01, -8.7989e-01, -1.1043e+01,  ..., -2.1440e+01,\n",
      "          -1.7488e+01, -6.6031e-01],\n",
      "         [-3.8513e+01, -1.0504e+01, -1.4457e+01,  ..., -2.0990e+01,\n",
      "          -1.7639e+01, -4.0389e+00],\n",
      "         ...,\n",
      "         [-4.5381e+01, -1.3927e+01, -1.5987e+01,  ..., -2.7031e+01,\n",
      "          -1.8505e+01, -3.2424e-05],\n",
      "         [-4.6487e+01, -1.3550e+01, -1.6364e+01,  ..., -2.8246e+01,\n",
      "          -1.9505e+01, -1.2875e-05],\n",
      "         [-4.5902e+01, -1.5548e+01, -1.6337e+01,  ..., -2.5513e+01,\n",
      "          -1.9933e+01, -5.4836e-06]],\n",
      "\n",
      "        [[-3.2509e+01, -5.3087e+00, -1.2013e+01,  ..., -1.7010e+01,\n",
      "          -1.8567e+01, -2.3093e+00],\n",
      "         [-3.8065e+01, -8.1668e+00, -1.2455e+01,  ..., -2.2971e+01,\n",
      "          -1.8331e+01, -2.8062e-02],\n",
      "         [-4.0653e+01, -1.0556e+01, -1.2842e+01,  ..., -2.5717e+01,\n",
      "          -1.6406e+01, -1.7128e-02],\n",
      "         ...,\n",
      "         [-4.7380e+01, -1.7597e+01, -1.9113e+01,  ..., -2.5768e+01,\n",
      "          -2.1070e+01, -9.5367e-07],\n",
      "         [-4.6968e+01, -1.6767e+01, -1.8075e+01,  ..., -2.6257e+01,\n",
      "          -2.1966e+01, -2.0266e-06],\n",
      "         [-4.4292e+01, -1.5139e+01, -1.6160e+01,  ..., -2.4001e+01,\n",
      "          -2.1730e+01, -4.0531e-06]],\n",
      "\n",
      "        [[-4.6128e+01, -1.6074e+01, -1.3728e+01,  ..., -1.9512e+01,\n",
      "          -1.9683e+01, -3.7603e-04],\n",
      "         [-4.9781e+01, -1.5462e+01, -1.6623e+01,  ..., -2.2577e+01,\n",
      "          -2.3569e+01, -1.5102e-02],\n",
      "         [-4.1606e+01, -1.2383e+01, -1.9927e+01,  ..., -2.2239e+01,\n",
      "          -2.2975e+01, -1.0568e+01],\n",
      "         ...,\n",
      "         [-4.3026e+01, -1.5823e+01, -1.5180e+01,  ..., -2.2007e+01,\n",
      "          -1.6761e+01, -2.0504e-05],\n",
      "         [-4.3342e+01, -1.5278e+01, -1.4560e+01,  ..., -2.1957e+01,\n",
      "          -1.8253e+01, -2.0504e-05],\n",
      "         [-4.3770e+01, -1.3909e+01, -1.3761e+01,  ..., -2.2722e+01,\n",
      "          -1.9403e+01, -1.8000e-05]]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([55, 55, 56, 56, 56, 57, 58, 58, 58, 59, 59, 59, 59, 59, 61, 61, 61, 61,\n",
      "        61, 62], device='cuda:0')\n",
      "tensor([[  1, 128,  72,  ..., 128, 128, 128],\n",
      "        [128, 128,  26,  ..., 128, 128, 128],\n",
      "        [ 18,  18,   4,  ..., 128, 128, 128],\n",
      "        ...,\n",
      "        [  1, 128,  34,  ..., 128, 128, 128],\n",
      "        [ 52, 128, 128,  ..., 128, 128, 128],\n",
      "        [128, 128,  16,  ..., 128, 128, 128]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "conformer.eval()\n",
    "log_pb, enc_len, gp = conformer(batch[\"audio\"], batch[\"audio_len\"])\n",
    "print(log_pb)\n",
    "print(enc_len)\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6cb19845",
   "metadata": {
    "cellId": "zi4a7eguq7le8ka5txuonc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ''), (1, ''), (2, 'да'), (3, ''), (4, 'й'), (5, ''), (6, ''), (7, 'б'), (8, ''), (9, 'о'), (10, ''), (11, ''), (12, 'г'), (13, ''), (14, ''), (15, 'что'), (16, ''), (17, ''), (18, 'б'), (19, 'б'), (20, ''), (21, 'про'), (22, ''), (23, ''), (24, ''), (25, 'с'), (26, ''), (27, 'в'), (28, 'ве'), (29, ''), (30, ''), (31, 'ти'), (32, ''), (33, ''), (34, ''), (35, ''), (36, 'ли'), (37, 'с'), (38, 'с'), (39, 'ь'), (40, 'ь'), (41, ''), (42, 'м'), (43, 'м'), (44, 'ы'), (45, ''), (46, ''), (47, ''), (48, ''), (49, ''), (50, ''), (51, ''), (52, ''), (53, ''), (54, ''), (55, ''), (56, ''), (57, ''), (58, ''), (59, ''), (60, ''), (61, '')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'дай бог чтоб просвветились мы'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "from src_my.metrics import ctc_greedy_decoding, beam_search_decoding\n",
    "\n",
    "print([(idx, sp_tokenizer.decode((token if token != 128 else 1))) for idx, token in enumerate(log_pb[0].argmax(dim=-1).tolist())])\n",
    "\n",
    "ctc_greedy_decoding(log_pb, enc_len, 128, sp_tokenizer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3632a041",
   "metadata": {
    "cellId": "ivycm9f7nbls3f5p1ruzf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ве', 'я', 'ре', 'е', 'ле', 'ви', 'и', 'у', 'ли', 'о']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "[sp_tokenizer.decode(token) for token in torch.topk(log_pb[0, 28], k=10).indices.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "21419d7c",
   "metadata": {
    "cellId": "y2h03654hpi0ygglpgns74"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6a610ba0e869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeam_search_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/Nazarov/conformer/src_my/metrics.py\u001b[0m in \u001b[0;36mbeam_search_decoding\u001b[0;34m(logits, logits_len, blank_id, tokenizer, beam_size)\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0mnew_hypos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                             new_prob_non_blank[(*string, token)] = np.logaddexp(new_prob_non_blank[(*string, token)],\n\u001b[0;32m---> 83\u001b[0;31m                                 \u001b[0mtokens_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogaddexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_blank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_non_blank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                             )\n\u001b[1;32m     85\u001b[0m             \u001b[0mlist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "beam_search_decoding(log_pb, enc_len, 128, sp_tokenizer, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ed87af2b",
   "metadata": {
    "cellId": "0bfz97m364no2xb71l0tb49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(128,)}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "{(128,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "481542b5",
   "metadata": {
    "cellId": "j1n54objxuuxcc9ifdu2l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'на ггде  же перрвый ззваный гость'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sp_tokenizer.decode(gp[1][gp[1] != 128].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fc7e4f67",
   "metadata": {
    "cellId": "xbnr4p7oqvg73o956dzsxo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777777777777777\n",
      "45\n",
      "26\n",
      "['дай бог чтоб просвветились мы', 'на где же первый званый гость', 'вот что хочет ссяне зоинька', 'м только лень и непоковство', 'теснимма шведов фрайд заратьюг', 'усоты куда свой танный путь', 'давновней и скорасгоралась', 'вн неемрачный дух неснал покоя']\n",
      "['дай бог чтоб просветились мы', 'но где же первый званый гость', 'вот что хочется мне зоинька', 'в нем только лень и непокорство', 'тесним мы шведов рать за ратью', 'куда свой тайный путь направил', 'давно в ней искра разгоралась', 'в нем мрачный дух не знал покоя']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from src.metrics import WERMetric\n",
    "\n",
    "metric = WERMetric(128, sp_tokenizer)\n",
    "\n",
    "reference = batch[\"text\"]\n",
    "\n",
    "metric.update(log_pb, enc_len, reference)\n",
    "\n",
    "wer, words, scores = metric.compute()\n",
    "print(wer, words, scores, sep=\"\\n\")\n",
    "print(hypothesis, reference, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7ea5f5dd",
   "metadata": {
    "cellId": "qwh6w6izaeane04ok3wap"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "a = conformer.loss(torch.transpose(log_pb, 0, 1), batch[\"tokens\"], enc_len, batch[\"tokens_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2582d",
   "metadata": {
    "cellId": "lcso9vyze1r1rk6r4g4cr2"
   },
   "outputs": [],
   "source": [
    "#!g1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "77fdacd0",
   "metadata": {
    "cellId": "086o86do1s05w0m2f4eulta"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:10<00:00, 14.48it/s]\n",
      "100%|██████████| 6153/6153 [14:45<00:00,  6.95it/s]\n",
      "100%|██████████| 148/148 [00:22<00:00,  6.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from src.train import evaluate\n",
    "\n",
    "wer_res_dev, ctc_res_dev = evaluate(conformer, sp_tokenizer, libri_speech_dev_dl, device)\n",
    "wer_res_train, ctc_res_train = evaluate(conformer, sp_tokenizer, libri_speech_train_dl, device)\n",
    "wer_res_test, ctc_res_test = evaluate(conformer, sp_tokenizer, libri_speech_test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "188965e6",
   "metadata": {
    "cellId": "7hxsf1wve79jjxnrfe97sm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5690275229357799, 13625, 7753)\n",
      "(0.48950873808021966, 539020, 263855)\n",
      "(0.573453975491593, 14036, 8049)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(wer_res_dev, wer_res_train, wer_res_test, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d5a32",
   "metadata": {
    "cellId": "aycf0w9m44r3m09fqph5lb",
    "execution_id": "80783292-4136-4e45-b609-d57eb8769ebc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b676aab2421e4b29a832b2ef23ddec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e9283f9fad4746a6c8126e25fe4224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "from src.train import train\n",
    "from src.scheduler import NoamAnnealing\n",
    "\n",
    "optimizer = torch.optim.AdamW(conformer.parameters(), lr=2, weight_decay=1e-3)\n",
    "scheduler = NoamAnnealing(optimizer, d_model=conformer.d_model, warmup_steps=600)\n",
    "\n",
    "train(conformer, sp_tokenizer, None, optimizer, scheduler, 10, libri_speech_dev_dl, validate_dataloaders, device, model_dir=\"model_train\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "eb70484e-b52c-49dd-8e10-23f8f003c2c9",
  "notebookPath": "Nazarov/conformer/Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
